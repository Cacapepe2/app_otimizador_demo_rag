import streamlit as st
import os
import pandas as pd
from lightrag import RAGPipeline
from lightrag.embeddings import HuggingFaceEmbedding
from lightrag.llms import OpenRouterLLM
from lightrag.vectorstores import FAISS
from lightrag.document_loaders import SimpleDirectoryReader

# Autentica√ß√£o com senha (segura com vari√°vel de ambiente)
def autenticar():
    senha_correta = os.getenv("APP_SENHA", "sem_senha")
    senha = st.text_input("üîê Digite a senha para acessar:", type="password")
    if senha != senha_correta:
        st.warning("Senha incorreta ou ausente.")
        st.stop()

autenticar()

st.title("üìÑ RAG T√©cnico para Telecomunica√ß√µes")

# Upload de arquivos
st.subheader("üì§ Envie seus documentos t√©cnicos e planilhas com dados")
uploaded_files = st.file_uploader("Arraste ou envie arquivos PDF, TXT, CSV", accept_multiple_files=True)

dados_df = None

if uploaded_files:
    os.makedirs("data", exist_ok=True)
    for file in uploaded_files:
        file_path = os.path.join("data", file.name)
        with open(file_path, "wb") as f:
            f.write(file.read())

        # Se for CSV, processa como DataFrame tamb√©m
        if file.name.endswith(".csv"):
            try:
                df_temp = pd.read_csv(file_path)
                if dados_df is None:
                    dados_df = df_temp
                else:
                    dados_df = pd.concat([dados_df, df_temp], ignore_index=True)
            except Exception as e:
                st.warning(f"Erro ao ler {file.name} como CSV: {e}")

    st.success("Documentos salvos com sucesso!")

    # Inicializa o pipeline RAG
    st.info("üîÑ Indexando os documentos...")
    documents = SimpleDirectoryReader("data").load()

    embed_model = HuggingFaceEmbedding("BAAI/bge-base-en-v1.5")
    vectorstore = FAISS.from_documents(documents, embed_model)

    llm = OpenRouterLLM(
        api_key=os.getenv("OPENROUTER_API_KEY"),  # vari√°vel de ambiente segura
        model="openai/gpt-3.5-turbo"
    )

    pipeline = RAGPipeline(retriever=vectorstore.as_retriever(), llm=llm)
    st.success("Documentos prontos para consulta.")

    # Interface de perguntas
    st.subheader("üîé Fa√ßa perguntas sobre os documentos e dados carregados")
    query = st.text_input("Digite sua pergunta t√©cnica:")
    if query:
        with st.spinner("Consultando documentos e dados..."):
            contexto_extra = ""
            if dados_df is not None:
                colunas_criticas = [col for col in dados_df.columns if any(palavra in col.lower() for palavra in ["taxa", "ue", "indice"])]
                dados_criticos = dados_df.copy()
                for col in colunas_criticas:
                    try:
                        dados_criticos = dados_criticos[dados_criticos[col] >= 8]
                    except:
                        pass  # ignora colunas n√£o num√©ricas
                contexto_extra = dados_criticos.to_string(index=False)
            result = pipeline.invoke(query + "\n\nDados cr√≠ticos:\n" + contexto_extra)
            st.markdown("### üß† Resposta")
            st.write(result)

# Exemplo de perguntas sugeridas
with st.expander("üí° Exemplos de perguntas t√©cnicas"):
    st.markdown("""
    - Quais sites com √≠ndice_taxa ou ue_medio igual a 10 precisam de aten√ß√£o?
    - Quais s√£o os piores valores registrados por munic√≠pio?
    - O que fazer com um site com alto ue_medio e √≠ndice de retransmiss√£o?
    - Existe alguma recomenda√ß√£o nos documentos para valores cr√≠ticos?
    - Como melhorar um site com valores ruins em v√°rias colunas?
    """)
